{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Silent_Night\\\\mlops\\\\AML_Classification\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Silent_Night\\\\mlops\\\\AML_Classification'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Humidity  Temperature  Step count  Stress Level\n",
      "0     21.33        90.33         123             1\n",
      "1     21.41        90.41          93             1\n",
      "2     27.12        96.12         196             2\n",
      "3     27.64        96.64         177             2\n",
      "4     10.87        79.87          87             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"D:/data/classification_data/stress_data/stress_300.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update entity(Specifiy the data type all the config and params yaml file variable)\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    #data_dir: Path\n",
    "    base_model_path: Path\n",
    "    params_n_estimators: list\n",
    "    params_max_depth: list\n",
    "    params_min_sample_split: list\n",
    "    params_min_sample_leaf: list\n",
    "    params_max_features: list\n",
    "    params_class_weight: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AML_Classifier.constants.__init__ import CONFIG_FILE_PATH,PARAMS_FILE_PATH\n",
    "from AML_Classifier.utils.common import read_yaml, create_directories\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the configration manager\n",
    "from AML_Classifier.constants.__init__ import CONFIG_FILE_PATH,PARAMS_FILE_PATH\n",
    "from AML_Classifier.utils.common import read_yaml, create_directories\n",
    "from pathlib import Path\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath = CONFIG_FILE_PATH,params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config= read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        #training_data = os.path.join(self.config.data_ingestion.root_dir,\"stress_300.csv\")\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            base_model_path = Path(config.base_model_path),\n",
    "            params_n_estimators = self.params.n_estimators,\n",
    "            params_max_depth = self.params.max_depth,\n",
    "            params_min_sample_split = self.params.min_samples_split,\n",
    "            params_min_sample_leaf = self.params.min_samples_leaf,\n",
    "            params_max_features = self.params.max_features,\n",
    "            params_class_weight = self.params.class_weight\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the compontents\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self,config: PrepareBaseModelConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load_model_data(self):\n",
    "        #Need to make this data ingestion dynamic\n",
    "        data=df\n",
    "        y=data[[\"Stress Level\"]]\n",
    "        x=data.drop([\"Stress Level\"],axis=1)\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Define the parameter grid\n",
    "        param_grid = {\n",
    "            'n_estimators': self.config.params_n_estimators,\n",
    "            #'max_depth': self.config.params_max_depth,\n",
    "            #'min_samples_split': self.config.params_min_sample_split,\n",
    "            #'min_samples_leaf': self.config.params_min_sample_leaf,\n",
    "            #'max_features': self.config.params_max_features\n",
    "            }\n",
    "        \n",
    "        # Initialize the classifier\n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "        # Fit the model\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Print the best parameters\n",
    "        print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "        # Evaluate the best model on the test set\n",
    "        tuned_model=RandomForestClassifier(**grid_search.best_params_)\n",
    "        tuned_model.fit(X_train,y_train)\n",
    "        # Prediction Value\n",
    "        y_pred=tuned_model.predict(X_test)\n",
    "        #eval accuracy\n",
    "        accuracy=metrics.accuracy_score(y_pred,y_test)\n",
    "        print(\"Test Set Accuracy:\", accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-28 13:09:44,738: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-06-28 13:09:44,745: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-28 13:09:44,747: INFO: common: created directory at: artifacts]\n",
      "[2024-06-28 13:09:44,749: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JOHN\\anaconda3\\envs\\AML\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\JOHN\\anaconda3\\envs\\AML\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100}\n",
      "Test Set Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config=config.get_prepare_base_model_config()\n",
    "    prepare_base_model= PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.load_model_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
