{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Silent_Night\\\\mlops\\\\AML_Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AML_Classifier import logger\n",
    "from AML_Classifier.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-27 15:28:30,674: INFO: 3440599255: >>>>>>> Stage Data Ingestion stage started <<<<<<<]\n",
      "[2024-06-27 15:28:31,053: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-06-27 15:28:31,070: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-27 15:28:31,076: INFO: common: created directory at: artifacts]\n",
      "[2024-06-27 15:28:31,076: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-06-27 15:28:31,719: INFO: credentials: Found credentials in shared credentials file: ~/.aws/credentials]\n",
      "[2024-06-27 15:28:36,317: INFO: data_ingestion: Downloaded data from amaterasu AWS bucket into the path artifacts/data_ingestion/data.csv]\n",
      "[2024-06-27 15:28:36,336: INFO: 3440599255: >>>>>>> Stage Data Ingestion stage Completed <<<<<<< \n",
      " x=========================================x]\n"
     ]
    }
   ],
   "source": [
    "STAGE_NAME=\"Data Ingestion stage\"\n",
    "\n",
    "try:\n",
    "    logger.info(f\">>>>>>> Stage {STAGE_NAME} started <<<<<<<\")\n",
    "    obj = DataIngestionTrainingPipeline()\n",
    "    obj.main()\n",
    "    logger.info(f\">>>>>>> Stage {STAGE_NAME} Completed <<<<<<< \\n x=========================================x\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class PredictionPipeline:\n",
    "    def __init__(self,pred_data):\n",
    "        self.pred_data=pd.DataFrame([pred_data])\n",
    "\n",
    "    def predict(self):\n",
    "        #Preprocess the data\n",
    "        #load the standard scaler\n",
    "        with open(\"artifacts/model_data/scaler_obj.pkl\",\"rb\") as file:\n",
    "            sc = pickle.load(file)\n",
    "\n",
    "        pred_data_sc=sc.transform(self.pred_data[['from_bank', 'to_bank', 'amount_received', 'amount_paid']])\n",
    "        pred_data_sc=pd.DataFrame(pred_data_sc, columns=['from_bank', 'to_bank', 'amount_received', 'amount_paid'])\n",
    "\n",
    "        #load the label encoders\n",
    "        pred_data_le=pd.DataFrame()\n",
    "        for i in ['receiving_currency', 'Payment_Currency', 'Payment Format']:\n",
    "            with open(f\"artifacts/model_data/le_{i}.pkl\",\"rb\") as file:\n",
    "                le=pickle.load(file)\n",
    "            pred_data_le[i]=le.transform(np.array(self.pred_data[[i]]).ravel())\n",
    "\n",
    "        #Concate the two scaled data\n",
    "        pred_data_scaled=pd.concat([pred_data_le,pred_data_sc],axis=1)\n",
    "\n",
    "        #Load the model\n",
    "        with open(\"artifacts/prepare_base_model/base_model.pkl\",\"rb\") as file:\n",
    "            model = pickle.load(file)\n",
    "\n",
    "        #predict the output\n",
    "        result=model.predict(pred_data_scaled)\n",
    "\n",
    "        #Return the result\n",
    "        if result[0]==1:\n",
    "            prediction=\"Laundering Transaction\"\n",
    "            return [{\"Prediction\": prediction}]\n",
    "        else:\n",
    "            prediction = \"Normal Transaction\"\n",
    "            return [{\"Prediction\": prediction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to be converted\n",
    "test_data = {\n",
    "    'receiving_currency' : \"US Dollar\",\n",
    "    'Payment_Currency' : \"US Dollar\",\n",
    "    'Payment Format' : \"Cash\",\n",
    "    'from_bank': 70,\n",
    "    'to_bank': 22661,\n",
    "    'amount_received': 70831.64,\n",
    "    'amount_paid' : 70831.64\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "#df_test = pd.DataFrame([test_data])\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=PredictionPipeline(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.__init__(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Prediction': 'Laundering Transaction'}]\n"
     ]
    }
   ],
   "source": [
    "x=cl.predict()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientApp:\n",
    "    def __init__(self,x_data):\n",
    "        #self.pred_data = pred_data\n",
    "        self.classifier = PredictionPipeline(pred_data=x_data)\n",
    "\n",
    "    def predict(self):\n",
    "        return self.classifier.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clapp=ClientApp(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Prediction': 'Laundering Transaction'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clapp.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
